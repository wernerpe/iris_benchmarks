{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def bernoulli_samples(probability, size=1):\n",
    "    \"\"\"\n",
    "    Generate samples from a Bernoulli distribution with a given probability.\n",
    "    \n",
    "    Args:\n",
    "        probability (float): The probability of success (event occurring).\n",
    "        size (int): The number of samples to draw. Default is 1.\n",
    "        \n",
    "    Returns:\n",
    "        numpy.ndarray: An array of size `size` containing the generated samples.\n",
    "    \"\"\"\n",
    "    return np.random.binomial(1, probability, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Collision fraction threshold p = 0.010\n",
      "rejection probability expected more than if not true 0.990\n",
      "required sample count 3685\n",
      "required_sample_count type 2 err \n",
      "3684.1361487904733\n"
     ]
    }
   ],
   "source": [
    "\n",
    "actual_frac_in_collision = 0.05\n",
    "termination_frac_in_collision = 0.01 #0.01\n",
    "\n",
    "#this is delta\n",
    "delta = 0.01\n",
    "\n",
    "tau = 0.5\n",
    "\n",
    "def compute_sample_count(delta, tau, p):\n",
    "    return 1/p*np.log(1/delta)*2/(tau**2)\n",
    "# , p' = {actual_frac_in_collision:.3f}\n",
    "\n",
    "#print(f\"p'<= {(1-tau)*termination_frac_in_collision/(1+tau_minus) :.3f}\")\n",
    "print(f\" Collision fraction threshold p = {termination_frac_in_collision:.3f}\")\n",
    "if actual_frac_in_collision>=termination_frac_in_collision:\n",
    "    print(f\"rejection probability expected more than if not true {1-delta:.3f}\")\n",
    "else:\n",
    "    print(f\"acceptance probability expected more than {1-delta:.3f} if p'<= {(1-tau)*termination_frac_in_collision/(1+tau_minus):.3f}\")\n",
    "\n",
    "prob_factor = 1/termination_frac_in_collision*np.log(1/delta)\n",
    "tau_factors = [2/(tau**2)] #, (2+tau_minus)*(1+tau_minus)/(tau_minus**2*(1-tau))\n",
    "required_sample_count = prob_factor*np.max(tau_factors)\n",
    "required_sample_count = int(np.ceil(required_sample_count))\n",
    "print(f\"required sample count {required_sample_count}\")\n",
    "string =f\"\"\"required_sample_count type 2 err \n",
    "{prob_factor*tau_factors[0]}\"\"\" #, power {prob_factor*tau_factors[1]}\n",
    "print(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Want iris region that is 0.99 % collision free with 0.99 certainty\n",
      "Iteration 1: Required samples 3286, threshold to pass: lower than 16.43 samples in collision\n",
      "Iteration 2: Required samples 4396, threshold to pass: lower than 21.98 samples in collision\n",
      "Iteration 3: Required samples 5044, threshold to pass: lower than 25.22 samples in collision\n",
      "Iteration 4: Required samples 5505, threshold to pass: lower than 27.53 samples in collision\n",
      "Iteration 5: Required samples 5862, threshold to pass: lower than 29.31 samples in collision\n",
      "Iteration 6: Required samples 6153, threshold to pass: lower than 30.77 samples in collision\n",
      "Iteration 7: Required samples 6400, threshold to pass: lower than 32.00 samples in collision\n",
      "Iteration 8: Required samples 6614, threshold to pass: lower than 33.07 samples in collision\n",
      "Iteration 9: Required samples 6802, threshold to pass: lower than 34.01 samples in collision\n"
     ]
    }
   ],
   "source": [
    "delta = 0.01\n",
    "p = 0.01\n",
    "tau = 0.5\n",
    "\n",
    "print(f'Want iris region that is {1-p} % collision free with {1-delta} certainty')\n",
    "\n",
    "def compute_sample_count(delta, tau, p):\n",
    "    return int(np.ceil(1/p*np.log(1/delta)*2/(tau**2)))\n",
    "\n",
    "for i in range(1,10):\n",
    "    delta_k = delta * np.pi**2/(6*(i**2))\n",
    "    N = compute_sample_count(delta_k, tau, p)\n",
    "    print(f\"Iteration {i}: Required samples {N}, threshold to pass: lower than {N*(1-tau)*p:.2f} samples in collision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_k = delta * np.pi**2/(6*(1000000**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25391"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_sample_count(delta_k, tau, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydrake.all import HPolyhedron\n",
    "import numpy as np\n",
    "\n",
    "hp = HPolyhedron.MakeBox(-np.ones(5),  np.ones(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.263788986222608"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp.MaximumVolumeInscribedEllipsoid().CalcVolume()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running 2000 experiments\n",
      "est_accept_prob 0.000\n",
      "est_rej_prob 1.000\n",
      "0.049952781546811396\n",
      " thresh 0.005\n"
     ]
    }
   ],
   "source": [
    "N_exp = 2000\n",
    "print(f\"running {N_exp} experiments\")\n",
    "res = []\n",
    "means = []\n",
    "for _ in range(N_exp):\n",
    "    mean = np.mean(bernoulli_samples(actual_frac_in_collision, required_sample_count))\n",
    "    result = 1.0 if mean<= (1-tau)*termination_frac_in_collision else 0\n",
    "    res.append(result)\n",
    "    means.append(mean)\n",
    "print(f\"est_accept_prob {np.mean(res):.3f}\")\n",
    "print(f\"est_rej_prob {1-np.mean(res):.3f}\")\n",
    "print(f\"{np.mean(means)}\")\n",
    "print(f\"thresh {(1-tau)*termination_frac_in_collision}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.051560379918588875"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision thresold 0.9p\n",
      "accept power at p'<=0.6923076923076923p\n"
     ]
    }
   ],
   "source": [
    "tau = 0.1\n",
    "tau_minus = 0.3\n",
    "print(f\"decision thresold {1-tau}p\")\n",
    "print(f\"accept power at p'<={(1-tau)/(1+tau_minus)}p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8121297265594456"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "\n",
    "N = 1000\n",
    "P0 = 0.90\n",
    "alpha_z = 1e-20\n",
    "mu = N*P0\n",
    "sigma= np.sqrt(N*P0*(1-P0))\n",
    "    \n",
    "norm.ppf(alpha_z, loc = mu, scale= sigma)/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "940.4603066420494"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "\n",
    "N = 1000\n",
    "collision_free = 0.9\n",
    "confidence = 1-1e-5\n",
    "sigma = np.sqrt(N*collision_free*(1-collision_free))\n",
    "norm.ppf(confidence, loc = N*collision_free, scale= sigma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "\n",
    "N = 100\n",
    "collision_free = 0.99\n",
    "confidence = 0.99\n",
    "sigma = np.sqrt(N*collision_free*(1-collision_free))\n",
    "res = norm.ppf(confidence, loc = N*collision_free, scale= sigma)\n",
    "np.min([N, res])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N 100 confidence 0.50 collision_free 0.99 #colfree particles 99\n",
      "N 500 confidence 0.50 collision_free 0.99 #colfree particles 495\n",
      "N 1000 confidence 0.50 collision_free 0.99 #colfree particles 990\n",
      " Warning max achieveable confidence ~0.843\n",
      "N 100 confidence 0.80 collision_free 0.99 #colfree particles 100\n",
      "N 500 confidence 0.80 collision_free 0.99 #colfree particles 497\n",
      "N 1000 confidence 0.80 collision_free 0.99 #colfree particles 993\n",
      " Warning max achieveable confidence ~0.843\n",
      "N 100 confidence 0.95 collision_free 0.99 #colfree particles 100\n",
      "N 500 confidence 0.95 collision_free 0.99 #colfree particles 499\n",
      "N 1000 confidence 0.95 collision_free 0.99 #colfree particles 995\n",
      " Warning max achieveable confidence ~0.843\n",
      "N 100 confidence 0.99 collision_free 0.99 #colfree particles 100\n",
      " Warning max achieveable confidence ~0.988\n",
      "N 500 confidence 0.99 collision_free 0.99 #colfree particles 500\n",
      "N 1000 confidence 0.99 collision_free 0.99 #colfree particles 997\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm, binom\n",
    "import numpy as np\n",
    "\n",
    "for confidence in [ 0.5, 0.8, 0.95, 0.99]:\n",
    "    for N in [100, 500, 1000]:\n",
    "\n",
    "        collision_free = 0.99\n",
    "        sigma = np.sqrt(N*collision_free*(1-collision_free))\n",
    "        res = int(norm.ppf(confidence, loc = N*collision_free, scale= sigma)+0.5)\n",
    "        intres = np.min([res, N])\n",
    "        max_achieveable_confidence = norm.cdf(N, loc = N*collision_free, scale= sigma)\n",
    "        if intres ==N:\n",
    "            print(f\" Warning max achieveable confidence ~{max_achieveable_confidence:.3f}\")\n",
    "        print(f\"N {N} confidence {confidence:.2f} collision_free {collision_free:.2f} #colfree particles {intres}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9949874371066204"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2815515655446004"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm.ppf(0.9, loc = 0, scale= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "once sort res 794 alg pick 274\n",
      "degrees_original oncesort 924.0 alg 922.0\n",
      "ERRRROOOOOOORR##########\n",
      "once sort res 294 alg pick 623\n",
      "degrees_original oncesort 930.0 alg 926.0\n",
      "ERRRROOOOOOORR##########\n",
      "once sort res 963 alg pick 768\n",
      "degrees_original oncesort 926.0 alg 925.0\n",
      "ERRRROOOOOOORR##########\n",
      "once sort res 223 alg pick 92\n",
      "degrees_original oncesort 929.0 alg 926.0\n",
      "ERRRROOOOOOORR##########\n",
      "once sort res 54 alg pick 776\n",
      "degrees_original oncesort 926.0 alg 926.0\n",
      "once sort res 54 alg pick 366\n",
      "degrees_original oncesort 926.0 alg 921.0\n",
      "ERRRROOOOOOORR##########\n",
      "once sort res 971 alg pick 355\n",
      "degrees_original oncesort 928.0 alg 928.0\n",
      "once sort res 7 alg pick 736\n",
      "degrees_original oncesort 926.0 alg 924.0\n",
      "ERRRROOOOOOORR##########\n",
      "once sort res 978 alg pick 983\n",
      "degrees_original oncesort 929.0 alg 925.0\n",
      "ERRRROOOOOOORR##########\n",
      "once sort res 987 alg pick 851\n",
      "degrees_original oncesort 934.0 alg 931.0\n",
      "ERRRROOOOOOORR##########\n",
      "once sort res 757 alg pick 714\n",
      "degrees_original oncesort 927.0 alg 925.0\n",
      "ERRRROOOOOOORR##########\n",
      "once sort res 809 alg pick 503\n",
      "degrees_original oncesort 929.0 alg 928.0\n",
      "ERRRROOOOOOORR##########\n",
      "once sort res 216 alg pick 247\n",
      "degrees_original oncesort 932.0 alg 930.0\n",
      "ERRRROOOOOOORR##########\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3768865/3468068895.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclique_members\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mis_clique_member\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;31m#nx.draw(g, node_color = ['r' if i else 'k' for i in is_clique_member])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/networkx/classes/graph.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, incoming_graph_data, **attr)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;31m# attempt to load graph with data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mincoming_graph_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m             \u001b[0mconvert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_networkx_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mincoming_graph_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_using\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m         \u001b[0;31m# load graph attributes (must be after convert)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/networkx/convert.py\u001b[0m in \u001b[0;36mto_networkx_graph\u001b[0;34m(data, create_using, multigraph_input)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_using\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_using\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                 raise nx.NetworkXError(\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/networkx/utils/backends.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, backend, *args, **kwargs)\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbackends\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m             \u001b[0;31m# Fast path if no backends are installed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;31m# Use `backend_name` in this function instead of `backend`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/networkx/convert_matrix.py\u001b[0m in \u001b[0;36mfrom_numpy_array\u001b[0;34m(A, parallel_edges, create_using, edge_attr)\u001b[0m\n\u001b[1;32m   1197\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_multigraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_directed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m         \u001b[0mtriples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtriples\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mu\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1199\u001b[0;31m     \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_edges_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtriples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1200\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/networkx/classes/graph.py\u001b[0m in \u001b[0;36madd_edges_from\u001b[0;34m(self, ebunch_to_add, **attr)\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_edges_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m         \"\"\"\n\u001b[0;32m-> 1016\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mebunch_to_add\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m             \u001b[0mne\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mne\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/networkx/convert_matrix.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1186\u001b[0m             \u001b[0mtriples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0medges\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1188\u001b[0;31m             \u001b[0mtriples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0medge_attr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpython_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0medges\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m     \u001b[0;31m# If we are creating an undirected multigraph, only add the edges from the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m     \u001b[0;31m# upper triangle of the matrix. Otherwise, add all the edges. This relies\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/networkx/convert_matrix.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1143\u001b[0m     \u001b[0;31m# Get a list of all the entries in the array with nonzero entries. These\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m     \u001b[0;31m# coordinates become edges in the graph. (convert to int from np.int64)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1145\u001b[0;31m     \u001b[0medges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m     \u001b[0;31m# handle numpy constructed data type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpython_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"void\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "graph = np.array([[0, 1, 1, 1, 1],\n",
    "                  [0, 0, 1, 1, 1],\n",
    "                  [0, 0, 0, 1, 1],\n",
    "                  [0, 0, 0, 0, 1],\n",
    "                  [0, 0, 0, 0, 0],\n",
    "                  ])\n",
    "\n",
    "triplets = [[0,1,1],\n",
    "            [0,2,1],\n",
    "            [1,2,1],\n",
    "            [3,6,1],\n",
    "            [3,7,1],\n",
    "            [3,8,1],\n",
    "            [4,6,1],\n",
    "            [4,7,1],\n",
    "            [4,8,1],\n",
    "            [5,6,1],\n",
    "            [5,7,1],\n",
    "            [5,8,1],\n",
    "            ]\n",
    "\n",
    "# graph = np.zeros((9,9))\n",
    "# for t in triplets:\n",
    "#     graph[t[0], t[1]] = t[2]\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "np.random.seed(0)\n",
    "for _ in range(100):\n",
    "    n = 1000\n",
    "    graph = np.zeros((n,n))\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            if np.random.rand()>0.1:\n",
    "                graph[i,j] = 1\n",
    "\n",
    "    graph = graph + graph.T\n",
    "\n",
    "    is_clique_member = np.zeros((graph.shape[0],))\n",
    "\n",
    "    def compute_degrees(graph):\n",
    "        degrees = []\n",
    "        for i in range(graph.shape[0]):\n",
    "            degrees.append(np.sum(graph[i, :]))\n",
    "        return degrees\n",
    "\n",
    "    def pick_best(degrees_sort_idx, available_nodes):\n",
    "        first_seen = False\n",
    "        for d in degrees_sort_idx:\n",
    "            if d in available_nodes:\n",
    "                first_seen = True\n",
    "            if d in available_nodes and first_seen:\n",
    "                return d\n",
    "\n",
    "    def update_available_nodes(adj_mat, point_to_add, available_nodes):\n",
    "        update = []\n",
    "        for a in available_nodes:\n",
    "            if adj_mat[a, point_to_add]:\n",
    "                if not a==point_to_add:\n",
    "                    update.append(a)\n",
    "        return update\n",
    "\n",
    "    def remove_non_neighbour_edges(curr_graph, point_to_add):\n",
    "        for i in range(curr_graph.shape[0]):\n",
    "            if not curr_graph[i, point_to_add]:\n",
    "                for j in range(curr_graph.shape[0]):\n",
    "                    curr_graph[i,j] = 0\n",
    "        return curr_graph\n",
    "    \n",
    "    available_nodes = np.arange(graph.shape[0])\n",
    "    clique_members = []\n",
    "\n",
    "    curr_graph = graph.copy()\n",
    "    degrees_original = compute_degrees(curr_graph)\n",
    "    degrees_original_argsort = np.argsort(degrees_original)[::-1] \n",
    "    while True:\n",
    "        degrees = compute_degrees(curr_graph)\n",
    "        #degrees_sort_idx = \n",
    "        point_to_add = np.argsort(degrees)[::-1][1] #pick_best(degrees_sort_idx, available_nodes)\n",
    "        alt_sol = pick_best(degrees_original_argsort, available_nodes)\n",
    "        print(f\"once sort res {alt_sol} alg pick {point_to_add}\")\n",
    "        print(f\"degrees_original oncesort {degrees_original[alt_sol]} alg {degrees_original[point_to_add]}\")\n",
    "        if(degrees_original[alt_sol] != degrees_original[point_to_add]):\n",
    "            print('ERRRROOOOOOORR##########')\n",
    "            break\n",
    "        clique_members.append(point_to_add)\n",
    "        available_nodes = update_available_nodes(curr_graph, point_to_add, available_nodes)\n",
    "        if len(available_nodes)== 0:\n",
    "            break\n",
    "        curr_graph = remove_non_neighbour_edges(curr_graph, point_to_add)\n",
    "\n",
    "    #fill in result\n",
    "    for i in clique_members:\n",
    "        is_clique_member[i] = 1 \n",
    "    g = nx.Graph(graph)\n",
    "\n",
    "#nx.draw(g, node_color = ['r' if i else 'k' for i in is_clique_member])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydrake.all import IrisOptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IrisOptions(require_sample_point_is_contained=False, iteration_limit=100, termination_threshold=0.02, relative_termination_threshold=0.001, configuration_space_margin=0.01, num_collision_infeasible_samples=5, configuration_obstacles [], prog_with_additional_constraints is not set, num_additional_constraint_infeasible_samples=5, random_seed=1234, mixing_steps=10)\n"
     ]
    }
   ],
   "source": [
    "io = IrisOptions()\n",
    "print(io)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../benchmarks/default_options/2DOFFLIPPER_12312354.yml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3186918/2226962967.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menv_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"../benchmarks/default_options/{e}_12312354.yml\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0myaml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../benchmarks/default_options/2DOFFLIPPER_12312354.yml'"
     ]
    }
   ],
   "source": [
    "from iris_environments.environments import env_names\n",
    "import yaml\n",
    "default = {\n",
    "    'require_sample_point_is_contained': True,\n",
    "    'iteration_limit': 100,\n",
    "    'termination_threshold': 0.02,\n",
    "    'relative_termination_threshold': 0.001,\n",
    "    'configuration_space_margin': 0.01,\n",
    "    'num_collision_infeasible_samples': 5,\n",
    "    'num_additional_constraint_infeasible_samples': 5,\n",
    "    'random_seed': 1234\n",
    "}\n",
    "\n",
    "for e in env_names:\n",
    "    with open(f\"../benchmarks/default_options/{e}_12312354.yml\", \"w\") as f:\n",
    "        yaml.dump(default, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = IrisOptions()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
